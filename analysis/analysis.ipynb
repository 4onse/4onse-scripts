{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from oatlib import sensor, method, oat_utils # https://gitlab.com/freewat/freewat/tree/develop/oat\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from datetime import timedelta\n",
    "import scipy\n",
    "import numpy as np\n",
    "from pandas import concat\n",
    "import pandas as pd\n",
    "import pylab as plot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_list = [\n",
    "    {\n",
    "        'name': '4onse',\n",
    "        'service': 'https://geoservice.ist.supsi.ch/4onse/sos',\n",
    "        'basic_auth': ('xx', 'xx'),\n",
    "        'observed_properties': [\n",
    "            {\n",
    "                'prop': 'temperature',\n",
    "                'csv': './output/PCB_temperature_orig.csv',\n",
    "                'unit': 'Celsius',\n",
    "                'aggregate_function': 'AVG',\n",
    "                'aggregate_interval': 'PT10M',\n",
    "                'observed_property': (\n",
    "                    'urn:ogc:def:parameter:x-istsos:1.0:meteo:air:temperature'\n",
    "                ),\n",
    "                'procedure': 'TREVANO_PCB',\n",
    "                'labels': {\n",
    "                    'name': 'Temperature',\n",
    "                    'unit': '$^\\circ$C',\n",
    "                    'x_limit_margin': 5,\n",
    "                    'y_limit_margin': 5,\n",
    "                    'limit': 1\n",
    "                },\n",
    "                'method': 'standard'\n",
    "            },\n",
    "            {\n",
    "                'prop': 'humidity',\n",
    "                'csv': './output/PCB_humidity_orig.csv',\n",
    "                'unit': '%',\n",
    "                'aggregate_function': 'AVG',\n",
    "                'aggregate_interval': 'PT10M',\n",
    "                'observed_property': (\n",
    "                    'urn:ogc:def:parameter:x-istsos:1.0:meteo:air:humidity'\n",
    "                ),\n",
    "                'procedure': 'TREVANO_PCB',\n",
    "                'labels': {\n",
    "                    'name': 'Humidity',\n",
    "                    'unit': '$^\\circ$C',\n",
    "                    'x_limit_margin': 5,\n",
    "                    'y_limit_margin': 5,\n",
    "                    'limit': 4\n",
    "                },\n",
    "                'method': 'standard'\n",
    "            },\n",
    "            {\n",
    "                'prop': 'pressure',\n",
    "                'csv': './output/PCB_Pressure_orig.csv',\n",
    "                'unit': 'hPa',\n",
    "                'aggregate_function': 'AVG',\n",
    "                'aggregate_interval': 'PT10M',\n",
    "                'observed_property': (\n",
    "                    'urn:ogc:def:parameter:x-istsos:1.0:meteo:air:pressure'\n",
    "                ),\n",
    "                'procedure': 'TREVANO_PCB',\n",
    "                'labels': {\n",
    "                    'name': 'Pressure',\n",
    "                    'unit': 'hPa',\n",
    "                    'x_limit_margin': 3,\n",
    "                    'y_limit_margin': 3,\n",
    "                    'limit': 1\n",
    "                },\n",
    "                'method': 'standard'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'SUPSI',\n",
    "        'service': 'xx',\n",
    "        'basic_auth': ('xx', 'xx'),\n",
    "        'observed_properties': [\n",
    "            {\n",
    "                'prop': 'temperature',\n",
    "                'csv': './output/SUPSI_temperature_orig.csv',\n",
    "                'unit': 'Celsius',\n",
    "                'aggregate_function': 'AVG',\n",
    "                'aggregate_interval': 'PT10M',\n",
    "                'observed_property': (\n",
    "                    'urn:ogc:def:parameter:x-istsos:1.0:meteo:air:temperature'\n",
    "                ),\n",
    "                'procedure': 'T_TRE',\n",
    "                'labels': {\n",
    "                    'name': 'Temperature',\n",
    "                    'unit': '$^\\circ$C',\n",
    "                    'x_limit_margin': 5,\n",
    "                    'y_limit_margin': 5,\n",
    "                    'limit': 1\n",
    "                },\n",
    "                'method': 'standard'\n",
    "            },\n",
    "            {\n",
    "                'prop': 'humidity',\n",
    "                'csv': './output/SUPSI_humidity_orig.csv',\n",
    "                'unit': '%',\n",
    "                'observed_property': (\n",
    "                    'urn:ogc:def:parameter:x-istsos:1.0:meteo:air:humidity'\n",
    "                ),\n",
    "                'procedure': 'H_TRE',\n",
    "                'aggregate_function': 'AVG',\n",
    "                'aggregate_interval': 'PT10M',\n",
    "                'labels': {\n",
    "                    'name': 'Humidity',\n",
    "                    'unit': '$^\\circ$C',\n",
    "                    'x_limit_margin': 5,\n",
    "                    'y_limit_margin': 5,\n",
    "                    'limit': 4\n",
    "                },\n",
    "                'method': 'standard'\n",
    "            },\n",
    "            {\n",
    "                'prop': 'Pressure',\n",
    "                'csv': './output/SUPSI_Pressure_orig.csv',\n",
    "                'unit': 'hPa',\n",
    "                'observed_property': (\n",
    "                    'urn:ogc:def:parameter:x-istsos:1.0:meteo:air:pressure'\n",
    "                ),\n",
    "                'aggregate_function': 'AVG',\n",
    "                'aggregate_interval': 'PT10M',\n",
    "                'procedure': 'B_TRE',\n",
    "                'labels': {\n",
    "                    'name': 'Pressure',\n",
    "                    'unit': 'hPa',\n",
    "                    'x_limit_margin': 3,\n",
    "                    'y_limit_margin': 3,\n",
    "                    'limit': 1\n",
    "                },\n",
    "                'method': 'standard'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareStation():\n",
    "    def __init__(self, sensors_list, event_time):\n",
    "        self.event_time = event_time\n",
    "        self.sensors_list = sensors_list\n",
    "        self.interval = timedelta(days=15)\n",
    "        self.legend_params = {\n",
    "            'legend.fontsize': 5,\n",
    "            'legend.handlelength': 2\n",
    "        }\n",
    "        \n",
    "    def check_compatibility(self):\n",
    "        if len(self.sensors_list)==2:\n",
    "            a_sensor_obs = self.sensors_list[0]['observed_properties']\n",
    "            b_sensor_obs = self.sensors_list[1]['observed_properties']\n",
    "            if len(a_sensor_obs) == len(b_sensor_obs):\n",
    "                for a_ob in a_sensor_obs:\n",
    "                    res = list(\n",
    "                        filter(\n",
    "                            lambda x:  x['observed_property'] == a_ob['observed_property'], b_sensor_obs\n",
    "                        )\n",
    "                    )\n",
    "                    if res[0]['unit'] == a_ob['unit']:\n",
    "                        if res[0]['aggregate_function'] == a_ob['aggregate_function']:\n",
    "                            if res[0]['aggregate_interval'] == a_ob['aggregate_interval']:\n",
    "                                return True\n",
    "                            else:\n",
    "                                raise Exception(\n",
    "                                    'The aggregate interval {} does not match the one chosen for the observed property {} in station {}.'.format(\n",
    "                                        a_ob['aggregate_interval'], res['observed_property'][0], self.sensors_list[1]['name']\n",
    "                                    )\n",
    "                                )\n",
    "                        else:\n",
    "                            raise Exception(\n",
    "                                'The aggregate function {} does not match the one chosen for the observed property {} in station {}.'.format(\n",
    "                                    a_ob['aggregate_function'], res['observed_property'][0], self.sensors_list[1]['name']\n",
    "                                )\n",
    "                            )\n",
    "                    else:\n",
    "                        raise Exception(\n",
    "                            'The unit {} used for the procedure {} does not exist in station {}.'.format(\n",
    "                                a_ob['unit'], a_ob['observed_property'][0], self.sensors_list[1]['name']\n",
    "                            )\n",
    "                        )\n",
    "                    \n",
    "            else:\n",
    "                raise Exception('The observed properties number of the sensors dismatches.')\n",
    "        else:\n",
    "            raise Exception('The comparison analysis needs two sensors.')\n",
    "            \n",
    "    # da istSOS\n",
    "    def fetch_data(self):\n",
    "        for sensor_i in self.sensors_list:\n",
    "            column_names = []\n",
    "            sensor_stats = None\n",
    "            id_obp = 0\n",
    "            for observed_property in sensor_i['observed_properties']:\n",
    "                print(\n",
    "                    'Event time --> {}'.format(self.event_time)\n",
    "                )\n",
    "                print(\n",
    "                    'Start fetching procedure: {}\\nObserved property: {}\\n'.format(\n",
    "                        sensor_i['name'], observed_property['prop']\n",
    "                    )\n",
    "                )\n",
    "                column_names_in = []\n",
    "                begin_end_time = self.event_time.split('/')\n",
    "                begin_time = parser.parse(begin_end_time[0])\n",
    "                end_time = parser.parse(begin_end_time[1])\n",
    "                next_start = begin_time\n",
    "                \n",
    "                while end_time >= next_start:\n",
    "                    if (next_start == end_time):\n",
    "                        break\n",
    "                    else:\n",
    "                        stop_time = next_start + self.interval\n",
    "                        event_time = '{}/{}'.format(\n",
    "                            next_start.isoformat(), stop_time.isoformat()\n",
    "                        )\n",
    "                        print(\n",
    "                            sensor_i['service'],\n",
    "                            observed_property['observed_property'],\n",
    "                            observed_property['procedure'],\n",
    "                            sensor_i['basic_auth'],\n",
    "                            observed_property['aggregate_function'],\n",
    "                            observed_property['aggregate_interval'],\n",
    "                            event_time\n",
    "                        )\n",
    "\n",
    "                        SENSOR_TMP = sensor.Sensor(\n",
    "                            name=sensor_i['name'],\n",
    "                            prop=observed_property['prop'],\n",
    "                            unit=observed_property['unit']\n",
    "                        )\n",
    "                        SENSOR_TMP.ts_from_istsos(\n",
    "                            service=sensor_i['service'],\n",
    "                            observed_property=observed_property['observed_property'],\n",
    "                            procedure=observed_property['procedure'],\n",
    "                            basic_auth=sensor_i['basic_auth'],\n",
    "                            aggregate_function=observed_property['aggregate_function'],\n",
    "                            aggregate_interval=observed_property['aggregate_interval'],\n",
    "                            event_time=event_time\n",
    "                        )\n",
    "                    if next_start == begin_time:\n",
    "                        SENSOR = SENSOR_TMP.copy()\n",
    "                    else:\n",
    "                        SENSOR.ts = concat([SENSOR.ts, SENSOR_TMP.ts], verify_integrity=True)\n",
    "                    if (next_start + self.interval) > end_time:\n",
    "                        next_start = end_time\n",
    "                    else:\n",
    "                        next_start += + self.interval\n",
    "                sensor_i['observed_properties'][id_obp]['df'] = SENSOR\n",
    "                MAX_COL = observed_property['prop'][0].upper()+'MAX'\n",
    "                TIME_MAX_COL = 'TIME_' + MAX_COL\n",
    "                MIN_COL = observed_property['prop'][0].upper()+'MIN'\n",
    "                TIME_MIN_COL = 'TIME_' + MIN_COL\n",
    "                MEAN_COL = observed_property['prop'][0].upper()+'MEAN'\n",
    "                COUNT = '{}_COUNT'.format(MEAN_COL)\n",
    "\n",
    "                daily_max = oat_utils.sensorStats(\n",
    "                    SENSOR, stat='max',\n",
    "                    column_name=MAX_COL\n",
    "                )\n",
    "                daily_min = oat_utils.sensorStats(\n",
    "                    SENSOR, stat='min',\n",
    "                    column_name=MIN_COL\n",
    "                )\n",
    "                daily_mean = oat_utils.sensorStats(\n",
    "                    SENSOR, stat='mean',\n",
    "                    column_name=MEAN_COL\n",
    "                )\n",
    "\n",
    "                column_names = column_names + [\n",
    "                    MAX_COL, TIME_MAX_COL, MIN_COL, TIME_MIN_COL, MEAN_COL, COUNT\n",
    "                ]\n",
    "\n",
    "                daily_stats = SENSOR.copy()\n",
    "\n",
    "                daily_stats.ts = daily_min.ts[[MIN_COL]].join(\n",
    "                    daily_min.ts[[TIME_MIN_COL]]\n",
    "                ).join(\n",
    "                    daily_max.ts[[MAX_COL]]\n",
    "                ).join(\n",
    "                    daily_max.ts[[TIME_MAX_COL]]\n",
    "                ).join(\n",
    "                    daily_mean.ts[[MEAN_COL]]\n",
    "                ).join(\n",
    "                    daily_mean.ts[[COUNT]]\n",
    "                )\n",
    "\n",
    "                if sensor_stats:\n",
    "                    for c in daily_stats.ts.columns.values:\n",
    "                        sensor_stats.ts = sensor_stats.ts.join(daily_stats.ts[c])\n",
    "                else:\n",
    "                    sensor_stats = daily_stats.copy()\n",
    "                id_obp+=1\n",
    "            sensor_i['stats'] = sensor_stats\n",
    "            sensor_stats.save_to_csv(\n",
    "                './output/' + sensor_i['name'] + '_daily_stats.csv', columns=column_names\n",
    "            )\n",
    "        print('#################\\nFetching ended.')\n",
    "        \n",
    "    def filter_stats(self, count, quality_index=None):\n",
    "        # data filtered on the count of data used for the mean calculation.\n",
    "\n",
    "        for sensor_i in self.sensors_list:\n",
    "            columns_name = sensor_i['stats'].ts.columns.values.tolist()\n",
    "            count_columns = list(filter(lambda x: 'COUNT' in x, columns_name))\n",
    "            sensor_i['stats_filtered'] = sensor_i['stats'].ts[sensor_i['stats'].ts[count_columns[0]]>=count]\n",
    "#                 dfs_filtered_1.append(sensor.ts[sensor.ts['HMEAN_COUNT']>=143])\n",
    "\n",
    "    def sync_stats(self):\n",
    "        \n",
    "        idx1 = pd.Index(self.sensors_list[0]['stats_filtered'].index.values)\n",
    "        idx2 = pd.Index(self.sensors_list[1]['stats_filtered'].index.values)\n",
    "        diff1 = idx2.difference(idx1)\n",
    "        diff2 = idx1.difference(idx2)\n",
    "        self.sensors_list[0]['stats_filtered_synced'] = self.sensors_list[0]['stats_filtered'].drop(diff2)\n",
    "        self.sensors_list[1]['stats_filtered_synced'] = self.sensors_list[1]['stats_filtered'].drop(diff1)\n",
    "        \n",
    "    def sync_dfs(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO --> Find a better way to sync DF\n",
    "        \"\"\"\n",
    "        \n",
    "        idx2_diff = []\n",
    "        idx1_diff = []\n",
    "\n",
    "        sensors_orig_list2 = []\n",
    "\n",
    "        for sensor_ in self.sensors_list:\n",
    "            for i in range(len(sensor_['observed_properties'])):\n",
    "                toat = sensor_['observed_properties'][i]\n",
    "                toat['df'].ts = sensor_['observed_properties'][i]['df'].ts.dropna(how='any')\n",
    "                sensor_['observed_properties'][i]['df_synced'] = toat['df']\n",
    "                sensors_orig_list2.append(toat)\n",
    "\n",
    "        for sensor_ in sensors_orig_list2:\n",
    "            idx1 = pd.Index(sensor_['df'].ts.index.values)\n",
    "            for i in sensors_orig_list2:\n",
    "                idx2 = pd.Index(i['df'].ts.index.values)\n",
    "                diff = idx2.difference(idx1)\n",
    "                if diff.size > 0:\n",
    "                    idx2_diff.append(diff)\n",
    "                diff = idx1.difference(idx2)\n",
    "                if diff.size > 0:\n",
    "                    idx1_diff.append(diff)\n",
    "\n",
    "\n",
    "        for sensor_ in self.sensors_list:\n",
    "            for i in range(len(sensor_['observed_properties'])):\n",
    "                toat = sensor_['observed_properties'][i]['df_synced'].copy()\n",
    "                for diff in idx1_diff:\n",
    "                    try:\n",
    "                        toat.ts = sensor_['observed_properties'][i]['df_synced'].ts.drop(diff)\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                for diff in idx2_diff:\n",
    "                    try:\n",
    "                        toat.ts = toat.ts.drop(diff)\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                sensor_['observed_properties'][i]['df_synced'] = toat\n",
    "\n",
    "    def plot_orig_values(self):\n",
    "        letters = ['a','b','c','d','e','f']\n",
    "        \n",
    "        for obp in self.sensors_list[0]['observed_properties']:\n",
    "            obp_ref = list(\n",
    "                filter(lambda x: x['observed_property'] == obp['observed_property'], self.sensors_list[1]['observed_properties'])\n",
    "            )[0]\n",
    "            obp_unit = obp['labels']['unit']\n",
    "            \n",
    "            label_ = '{}_{}'.format(obp['prop'][0].upper(), obp['df'].name)\n",
    "            label_ref = '{}_{}'.format(obp_ref['prop'][0].upper(), obp_ref['df'].name)\n",
    "            obp['df'].ts['data'].plot(legend=True, label=label_)\n",
    "            obp_ref['df'].ts['data'].plot(legend=True, label=label_ref)\n",
    "\n",
    "\n",
    "            plt.ylabel('{} ({})'.format(obp['labels']['name'], obp['labels']['unit']))\n",
    "            plt.xlabel('Date')\n",
    "            plt.legend(loc='best', fontsize='medium')\n",
    "            plt.savefig('{}_full.png'.format(obp['prop']))\n",
    "            plt.close()\n",
    "            A_matrix = obp['df_synced'].ts['data'].values\n",
    "            B_matrix = obp_ref['df_synced'].ts['data'].values\n",
    "            matrix =  np.concatenate(\n",
    "                (\n",
    "                    obp['df'].ts.dropna()['data'].as_matrix(),\n",
    "                    obp_ref['df'].ts.dropna()['data'].as_matrix()\n",
    "                ), axis=0\n",
    "            )\n",
    "            print(\n",
    "                '%s R-squared (Pearson): %s \\n%s R-squared (Kendall): %s \\n%s R-squared (Speaman): %s' % (\n",
    "                    obp['labels']['name'], obp['df_synced'].ts['data'].corr(obp_ref['df_synced'].ts['data']),\n",
    "                    obp['labels']['name'], obp['df_synced'].ts['data'].corr(obp_ref['df_synced'].ts['data'], method='kendall'),\n",
    "                    obp['labels']['name'], obp['df_synced'].ts['data'].corr(obp_ref['df_synced'].ts['data'], method='spearman')\n",
    "                )\n",
    "            )\n",
    "            # scatter plot\n",
    "            plt.title('{})'.format(letters[0]), loc='left')\n",
    "            percentiles = [np.percentile(matrix, 5), np.percentile(matrix, 95)]\n",
    "            residuals = obp['df_synced'].ts - obp_ref['df_synced'].ts\n",
    "            quantiles = [\n",
    "                residuals.dropna().quantile(.05)['data'],\n",
    "                residuals.dropna().quantile(.95)['data']\n",
    "            ]\n",
    "            min_1 = obp['df_synced'].ts['data'].min()\n",
    "            min_2 = obp_ref['df_synced'].ts['data'].min()\n",
    "            max_1 = obp['df_synced'].ts['data'].max()\n",
    "            max_2 = obp_ref['df_synced'].ts['data'].max()\n",
    "            if min_1 < min_2:\n",
    "                x_limit = min_1 - 5\n",
    "            else:\n",
    "                x_limit = min_2 - 5\n",
    "            if max_1 < max_2:\n",
    "                y_limit = max_2 + 5\n",
    "            else:\n",
    "                y_limit = max_1 + 5\n",
    "\n",
    "            limit_num = obp['labels']['limit']\n",
    "            limit_label = '{} {}'.format(limit_num, obp_unit)\n",
    "\n",
    "            plt.plot(\n",
    "                [\n",
    "                    x_limit,\n",
    "                    y_limit\n",
    "                ],[\n",
    "                    x_limit,\n",
    "                    y_limit\n",
    "                ], c='black', linewidth=1\n",
    "            )\n",
    "            plt.plot(\n",
    "                [\n",
    "                    obp['df_synced'].ts.dropna()['data'].min(),\n",
    "                    obp['df_synced'].ts.dropna()['data'].max()\n",
    "                ],[\n",
    "                    obp['df_synced'].ts.dropna()['data'].min()+limit_num,\n",
    "                    obp['df_synced'].ts.dropna()['data'].max()+limit_num\n",
    "                ], c='green', linestyle='dashed', linewidth=1, label='-%s limit' % (limit_label)\n",
    "            )\n",
    "\n",
    "            plt.plot(\n",
    "                [\n",
    "                    obp['df_synced'].ts.dropna()['data'].min(),\n",
    "                    obp['df_synced'].ts.dropna()['data'].max()\n",
    "                ],[\n",
    "                    obp['df_synced'].ts.dropna()['data'].min()-limit_num,\n",
    "                    obp['df_synced'].ts.dropna()['data'].max()-limit_num\n",
    "                ], c='red', linestyle='dashed', linewidth=1, label='+%s limit' % (limit_label)\n",
    "            )\n",
    "            scatter_plot = plt.scatter(A_matrix, B_matrix, marker='+')\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([x_limit,y_limit])\n",
    "            axes.set_ylim([x_limit,y_limit])\n",
    "\n",
    "\n",
    "            plt.xlabel('{} {} ({})'.format(obp['labels']['name'], obp['labels']['unit'], obp['df_synced'].name))\n",
    "            plt.ylabel('{} {} ({})'.format(obp['labels']['name'], obp['labels']['unit'], obp_ref['df_synced'].name))\n",
    "            plt.legend(loc='best', fontsize='medium')\n",
    "            plt.savefig('{}_scatter.png'.format(obp['prop']))\n",
    "            plt.close()\n",
    "            \n",
    "            # density plot\n",
    "            min_ = residuals['data'].min()\n",
    "            max_ = residuals['data'].max()\n",
    "            x_limit_sx = min_ - limit_num\n",
    "            x_limit_dx = max_ + limit_num\n",
    "            plt.title('{})'.format(letters[0]), loc='left')\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([x_limit_sx,x_limit_dx])\n",
    "            res_plt_den = residuals['data'].plot.density()\n",
    "            plt.xlabel('{} {} ({})'.format(obp['labels']['name'], obp['labels']['unit'], obp['df_synced'].name))\n",
    "            mean_val = residuals['data'].mean()\n",
    "            std_val = residuals['data'].std()\n",
    "            print('Mean abs error: %s' % (mean_val))\n",
    "            print('Std error: %s' % (std_val))\n",
    "            print('First quantile, second quantile: {}, {}'.format(quantiles[0], quantiles[1]))\n",
    "            plt.axvline(mean_val, c= 'black', linestyle='dashed', linewidth=1, label='Mean')\n",
    "            res_plt_den.axvspan(quantiles[0], quantiles[1], alpha=0.3, color='red', label=\"2$\\sigma$\")\n",
    "            plt.legend(loc='best', fontsize='medium')\n",
    "            plt.savefig('{}_density.png'.format(obp['prop']))\n",
    "            plt.close()\n",
    "            \n",
    "\n",
    "    def plot_stats_values_residuals(self):\n",
    "        \n",
    "        print('Plotting')\n",
    "        plot.rcParams.update(self.legend_params)\n",
    "        letters = ['a','b','c','d','e','f']\n",
    "        \n",
    "        columns = self.sensors_list[0]['stats_filtered_synced'].columns.values\n",
    "\n",
    "        s_1 = sensors_list[0]['name']\n",
    "        s_2 = sensors_list[1]['name']\n",
    "        first_sensor = sensors_list[0]['stats_filtered_synced']\n",
    "\n",
    "        second_sensor = sensors_list[1]['stats_filtered_synced']\n",
    "        residuals = first_sensor - second_sensor\n",
    "        id_col = 0\n",
    "        for col in columns:\n",
    "            if 'COUNT' not in col:\n",
    "                col_ = '{}_{}'.format(col, s_1)\n",
    "                col_ref = '{}_{}'.format(col, s_2)\n",
    "                col_res = '{}_RESIDUALS'.format(col)\n",
    "                file_name = '{}_res.png'.format(col)\n",
    "                scatter_name = '{}_scatter_plot.png'.format(col)\n",
    "                residual_name = '{}_residual_plot.png'.format(col)\n",
    "                density_name = '{}_density_plot.png'.format(col)\n",
    "                id_obp = int(id_col/6)\n",
    "                obp_name = sensors_list[0]['observed_properties'][id_obp]['labels']['name']\n",
    "                obp_unit = sensors_list[0]['observed_properties'][id_obp]['labels']['unit']\n",
    "                sensors_list[0]['observed_properties'][id_obp]['labels']['name']\n",
    "                scatter_x_label = '{} {} ({})'.format(obp_name, obp_unit, s_1)\n",
    "                scatter_y_label = '{} {} ({})'.format(obp_name, obp_unit, s_2)\n",
    "                scatter_y_residual_label = 'Residuals {} ({})'.format(col, obp_unit)\n",
    "                gen_label = '{} {}'.format(obp_name, obp_unit)\n",
    "                res_label = 'Residuals {}'.format(obp_unit)\n",
    "                id_col+=1\n",
    "\n",
    "\n",
    "                if 'TIME' not in col:\n",
    "                    first_sensor[col].plot(legend=True, label=col_)\n",
    "                    second_sensor[col].plot(legend=True, label=col_ref)\n",
    "                    plt.ylabel(gen_label)\n",
    "                    plt.xlabel('Date')\n",
    "                    plt.legend(loc='best', fontsize='medium')\n",
    "                    plt.savefig(file_name)\n",
    "                    plt.close()\n",
    "                    A_matrix = first_sensor[col].values\n",
    "                    B_matrix = second_sensor[col].values\n",
    "\n",
    "                    matrix =  np.concatenate(\n",
    "                        (\n",
    "                            first_sensor.dropna()[col].values,\n",
    "                            second_sensor.dropna()[col].values\n",
    "                        ), axis=0\n",
    "                    )\n",
    "\n",
    "                    print(\n",
    "                        '%s R-squared (Pearson): %s \\n%s R-squared (Kendall): %s \\n%s R-squared (Speaman): %s' % (\n",
    "                            col, first_sensor[col].corr(second_sensor[col]),\n",
    "                            col, first_sensor[col].corr(second_sensor[col], method='kendall'),\n",
    "                            col, first_sensor[col].corr(second_sensor[col], method='spearman')\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # scatter plot\n",
    "                    percentiles = [np.percentile(matrix, 5), np.percentile(matrix, 95)]\n",
    "                    residuals = first_sensor - second_sensor\n",
    "                    quantiles = [\n",
    "                        residuals.dropna().quantile(.05)[col],\n",
    "                        residuals.dropna().quantile(.95)[col]\n",
    "                    ]\n",
    "                    min_1 = first_sensor[col].min()\n",
    "                    min_2 = second_sensor[col].min()\n",
    "                    max_1 = first_sensor[col].max()\n",
    "                    max_2 = second_sensor[col].max()\n",
    "                    if min_1 < min_2:\n",
    "                        x_limit = min_1 - sensors_list[0]['observed_properties'][id_obp]['labels']['x_limit_margin']\n",
    "                    else:\n",
    "                        x_limit = min_2 - sensors_list[0]['observed_properties'][id_obp]['labels']['x_limit_margin']\n",
    "                    if max_1 < max_2:\n",
    "                        y_limit = max_2 + sensors_list[0]['observed_properties'][id_obp]['labels']['y_limit_margin']\n",
    "                    else:\n",
    "                        y_limit = max_1 + sensors_list[0]['observed_properties'][id_obp]['labels']['y_limit_margin']\n",
    "\n",
    "                    limit_num = sensors_list[0]['observed_properties'][id_obp]['labels']['limit']\n",
    "                    limit_label = '{} {}'.format(limit_num, obp_unit)\n",
    "                    if 'MIN' in col:\n",
    "                        plt.title('{})'.format(letters[2]), loc='left')\n",
    "                    elif 'MAX' in col:\n",
    "                        plt.title('{})'.format(letters[1]), loc='left')\n",
    "                    elif 'MEAN' in col:\n",
    "                        plt.title('{})'.format(letters[3]), loc='left')\n",
    "                    plt.plot(\n",
    "                        [\n",
    "                            x_limit,\n",
    "                            y_limit\n",
    "                        ],[\n",
    "                            x_limit,\n",
    "                            y_limit\n",
    "                        ], c='black', linewidth=1\n",
    "                    )\n",
    "                    plt.plot(\n",
    "                        [\n",
    "                            first_sensor.dropna()[col].min(),\n",
    "                            first_sensor.dropna()[col].max()\n",
    "                        ],[\n",
    "                            first_sensor.dropna()[col].min()+limit_num,\n",
    "                            first_sensor.dropna()[col].max()+limit_num\n",
    "                        ], c='green', linestyle='dashed', linewidth=1, label='-%s limit' % (limit_label)\n",
    "                    )\n",
    "\n",
    "                    plt.plot(\n",
    "                        [\n",
    "                            first_sensor.dropna()[col].min(),\n",
    "                            first_sensor.dropna()[col].max()\n",
    "                        ],[\n",
    "                            first_sensor.dropna()[col].min()-limit_num,\n",
    "                            first_sensor.dropna()[col].max()-limit_num\n",
    "                        ], c='red', linestyle='dashed', linewidth=1, label='+%s limit' % (limit_label)\n",
    "                    )\n",
    "                    scatter_plot = plt.scatter(A_matrix, B_matrix, marker='+')\n",
    "                    axes = plt.gca()\n",
    "                    axes.set_xlim([x_limit,y_limit])\n",
    "                    axes.set_ylim([x_limit,y_limit])\n",
    "\n",
    "                    plt.xlabel(scatter_x_label)\n",
    "                    plt.ylabel(scatter_y_label)\n",
    "                    plt.legend(loc='best', fontsize='medium')\n",
    "                    plt.savefig(scatter_name)\n",
    "                    plt.close()\n",
    "\n",
    "                    # density plot\n",
    "                    res_plt_den = residuals[col].plot.density()\n",
    "                    plt.xlabel(gen_label)\n",
    "                    mean_val = residuals[col].mean()\n",
    "                    std_val = residuals[col].std()\n",
    "                    if 'MIN' in col:\n",
    "                        plt.title('{})'.format(letters[2]), loc='left')\n",
    "                    elif 'MAX' in col:\n",
    "                        plt.title('{})'.format(letters[1]), loc='left')\n",
    "                    elif 'MEAN' in col:\n",
    "                        plt.title('{})'.format(letters[3]), loc='left')\n",
    "                    print('Mean error: %s' % mean_val)\n",
    "                    print('Std: %s' % std_val)\n",
    "                    print('First quantile, second quantile: {}, {}'.format(quantiles[0], quantiles[1]))\n",
    "                    plt.axvline(mean_val, c= 'black', linestyle='dashed', linewidth=1, label='Mean')\n",
    "                    res_plt_den.axvspan(quantiles[0], quantiles[1], alpha=0.3, color='red', label=\"2$\\sigma$\")\n",
    "                    plt.legend(loc='best', fontsize='medium')\n",
    "                    plt.savefig(density_name)\n",
    "                    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_time = ('2018-07-01T00:00:00.000000Z/2018-02-28T00:00:00.000000Z')\n",
    "cc = CompareStation(sensors_list, event_time)\n",
    "if cc.check_compatibility():\n",
    "    cc.fetch_data()\n",
    "\n",
    "    cc.filter_stats(143)\n",
    "\n",
    "    cc.sync_stats()\n",
    "\n",
    "    cc.sync_dfs()\n",
    "\n",
    "    cc.plot_orig_values()\n",
    "\n",
    "    cc.plot_stats_values_residuals()\n",
    "else:\n",
    "    print('Procedures are not compatible')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
